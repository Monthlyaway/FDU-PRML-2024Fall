{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa9e6fb23a5356",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "In this exercise, you will complete the implementation of a Decision Tree classifier based on our simple `fduml` framework. We have written most of the code for you already, and you only need to fill in the most essential parts marked in `TODO`. We have also prepared several test cases for you to check if your code works correctly. Furthermore, you can also test the accuracy of your code by comparing its output with the output of Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc42f1d4c0679bec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Auto reload external modules, which means you can modify the code of our fduml implementation without restarting the kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbac084f253b88a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b847afee6a108d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implement and test (40 points)\n",
    "\n",
    "We have prepared several test cases for you to check if your code works correctly. After you write your own implementation, try the following code for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df4695e706b454e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fduml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864192717f0f9a52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info_gain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfduml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_decision_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_dt_classification\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtest_dt_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\FDU-PRML-2024Fall\\Exercise\\Exercise2\\fduml\\tree\\tests\\test_decision_tree.py:18\u001b[0m, in \u001b[0;36mtest_dt_classification\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m true_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m dt_clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(criterion\u001b[38;5;241m=\u001b[39mcriterion, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mdt_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(X)\n\u001b[0;32m     20\u001b[0m assert_array_equal(dt_clf\u001b[38;5;241m.\u001b[39mpredict(T), true_result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(criterion))\n",
      "File \u001b[1;32md:\\Code\\FDU-PRML-2024Fall\\Exercise\\Exercise2\\fduml\\tree\\decision_tree.py:100\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     98\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# normalize feature scores\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_scores_\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "File \u001b[1;32md:\\Code\\FDU-PRML-2024Fall\\Exercise\\Exercise2\\fduml\\tree\\decision_tree.py:121\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, curr_depth)\u001b[0m\n\u001b[0;32m    119\u001b[0m split_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split \u001b[38;5;129;01mand\u001b[39;00m curr_depth \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth:\n\u001b[1;32m--> 121\u001b[0m     split, split_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m leaf_num_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_leaf_num\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_score \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_split:\n",
      "File \u001b[1;32md:\\Code\\FDU-PRML-2024Fall\\Exercise\\Exercise2\\fduml\\tree\\decision_tree.py:187\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._split\u001b[1;34m(self, X, y, splitter)\u001b[0m\n\u001b[0;32m    184\u001b[0m l_y \u001b[38;5;241m=\u001b[39m y[l]\n\u001b[0;32m    185\u001b[0m r_y \u001b[38;5;241m=\u001b[39m y[r]\n\u001b[1;32m--> 187\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m max_score:\n\u001b[0;32m    189\u001b[0m     l_Xy \u001b[38;5;241m=\u001b[39m X[l, :]\n",
      "File \u001b[1;32md:\\Code\\FDU-PRML-2024Fall\\Exercise\\Exercise2\\fduml\\tree\\criterion.py:57\u001b[0m, in \u001b[0;36m__info_gain\u001b[1;34m(y, l_y, r_y)\u001b[0m\n\u001b[0;32m     46\u001b[0m all_labels, left_labels, right_labels \u001b[38;5;241m=\u001b[39m __label_stat(y, l_y, r_y)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m###########################################################################\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# TODO:                                                                   #\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Implement this method. Calculate the info gain if splitting y into      #\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minfo_gain\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'info_gain' is not defined"
     ]
    }
   ],
   "source": [
    "from fduml.tree.tests.test_decision_tree import test_dt_classification\n",
    "test_dt_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9f980",
   "metadata": {},
   "source": [
    "## Load data and fit the model (40 points)\n",
    "\n",
    "Inside the `data` directory we have prepared a classification dataset, split into training and test sets. In this part, you will load the data and fit the model to the training data. Then, you will evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the water potability dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74846e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a DecisionTreeClassifier to the water potability train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c07ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the DecisionTreeClassifier on the water potability test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865aa4552324124",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compare with Sklearn (20 points)\n",
    "\n",
    "Since the interface of our `fduml` is the same as that of sklearn, you can easily compare the output of your implementation with that of sklearn. In this part, try to generate test data and compare the accuracy and running time of your implementation with that of sklearn. You can use the following code for comparison.\n",
    "\n",
    "In the conclusion part, try to answer the following questions:\n",
    "\n",
    "- Is the accuracy of your implementation the same as that of sklearn? If not, what can be the reason?\n",
    "\n",
    "- Is the running time of your implementation the same as that of sklearn? If not, what can be the reason?\n",
    "\n",
    "- If there is any special thing you want to mention, please write it down.\n",
    "\n",
    "Note that we do not require you to match the accuracy and running time of sklearn (which can be quite difficult), but you should be able to explain the reason if they are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7521a793b9a5488",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499ef0501ed482fb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816b68f11484697",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
