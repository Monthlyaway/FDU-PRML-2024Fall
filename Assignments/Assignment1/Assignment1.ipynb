{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDU PRML 2024 Fall Assignment 1\n",
    "\n",
    "Name: 杨淳瑜\n",
    "\n",
    "Student ID: 22307140114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructions and complete the following exercises using PyTorch.\n",
    "\n",
    "## 1. Basic Operations of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Tensor:\n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Second Tensor:\n",
      " tensor([[ 0.8525,  0.4192, -0.6536,  0.2636],\n",
      "        [-0.8784, -0.3854,  1.1727,  0.2847],\n",
      "        [-1.4434,  0.2666, -0.2627,  0.9754]])\n",
      "Matrix Product:\n",
      " tensor([[ 0.8817,  0.1936, -0.4640],\n",
      "        [ 0.8817,  0.1936, -0.4640],\n",
      "        [ 0.8817,  0.1936, -0.4640]])\n",
      "Concatenation:\n",
      " tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.8525,  0.4192, -0.6536,  0.2636],\n",
      "        [-0.8784, -0.3854,  1.1727,  0.2847],\n",
      "        [-1.4434,  0.2666, -0.2627,  0.9754]])\n",
      "Stacked Tensor:\n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "Stacked Tensor Shape:\n",
      " torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# TODO: assign a tensor of shape (3, 4) with all elements equal to 1.0\n",
    "my_first_tensor = torch.ones((3, 4))\n",
    "\n",
    "# TODO: assign a random tensor of shape (3, 4) with all elements sampled from a standard normal distribution\n",
    "my_second_tensor = torch.randn((3, 4))\n",
    "\n",
    "# TODO: compute the matrix product of my_first_tensor and the transpose of my_second_tensor (There are multiple ways to do this. Just pick one you like.)\n",
    "their_matrix_product = my_first_tensor @ my_second_tensor.T\n",
    "\n",
    "# TODO: concatenate my_first_tensor and my_second_tensor along the first dimension. (Maybe you should check the documentation of torch.cat)\n",
    "some_meaningless_concatenation = torch.cat(\n",
    "    (my_first_tensor, my_second_tensor), dim=0)\n",
    "\n",
    "# TODO: stack 5 copies of my_first_tensor along a newly created dimension. (Maybe you should check the documentation of torch.stack)\n",
    "some_meaningless_stack = torch.stack([my_first_tensor] * 5)\n",
    "\n",
    "# What is the shape of some_meaningless_stack? Can you imagine the geometric interpretation of stacking 5 matrices of shape (3, 4) along the first dimension?\n",
    "\n",
    "print(\"First Tensor:\\n\", my_first_tensor)\n",
    "print(\"Second Tensor:\\n\", my_second_tensor)\n",
    "print(\"Matrix Product:\\n\", their_matrix_product)\n",
    "print(\"Concatenation:\\n\", some_meaningless_concatenation)\n",
    "print(\"Stacked Tensor:\\n\", some_meaningless_stack)\n",
    "print(\"Stacked Tensor Shape:\\n\", some_meaningless_stack.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 images of shape (3, 4) is stacked to form a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A simple logistic regression\n",
    "\n",
    "There are 4 core components in Pytorch training process: **model**, **loss function**, **optimizer** and **data loader**. In this part, we will implement a simple logistic regression model to illustrate them.\n",
    "\n",
    "### 2.1 Model and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear layer for logitstic regression\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: initialize the weight and bias of the linear layer.\n",
    "        self.W = nn.Parameter(torch.randn((input_dim, output_dim),\n",
    "                                          dtype=torch.float32) * 0.01)\n",
    "        self.b = nn.Parameter(torch.zeros((1, output_dim), dtype=torch.float32)\n",
    "                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: implement the forward function of a linear layer.\n",
    "        y = x @ self.W + self.b\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(y_pred, y):\n",
    "\n",
    "    # TODO: implement the loss function of logistic regression.\n",
    "\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    loss = - (y * torch.log(y_pred + 1e-10) +\n",
    "              (1-y) * torch.log(1-y_pred + 1e-10))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data\n",
    "\n",
    "In real world, we usually have to deal with large-scale datasets. However, in this assignment, we will use synthetic data to illustrate the training process. The synthetic data is generated by the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random data for binary classification\n",
    "\n",
    "num_samples = 100\n",
    "num_features = 2\n",
    "\n",
    "x_0 = torch.randn(num_samples, num_features) + torch.tensor([2.0, 2.0])\n",
    "y_0 = torch.zeros(num_samples)\n",
    "\n",
    "x_1 = torch.randn(num_samples, num_features) + torch.tensor([-2.0, -2.0])\n",
    "y_1 = torch.ones(num_samples)\n",
    "\n",
    "x = torch.cat([x_0, x_1], dim=0)\n",
    "y = torch.cat([y_0, y_1], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8841,  1.2222],\n",
      "        [ 3.2002,  3.2312],\n",
      "        [ 1.1407,  1.2867],\n",
      "        [ 1.7542,  3.8392],\n",
      "        [ 2.4009,  0.1025],\n",
      "        [ 2.1433, -0.2142],\n",
      "        [ 1.5510,  2.7493],\n",
      "        [ 1.3016,  2.0296],\n",
      "        [ 2.9917,  1.0229],\n",
      "        [ 2.0267,  0.0106],\n",
      "        [ 2.1164,  1.2950],\n",
      "        [ 1.7138,  1.8569],\n",
      "        [ 3.1717,  1.3961],\n",
      "        [ 0.7440,  2.1238],\n",
      "        [ 3.3284,  2.7743],\n",
      "        [ 1.9353,  1.9335],\n",
      "        [ 2.3265,  3.5450],\n",
      "        [ 3.8190,  2.0069],\n",
      "        [ 1.3872,  3.4675],\n",
      "        [ 4.5128,  0.3142],\n",
      "        [ 1.9268,  3.4818],\n",
      "        [ 3.1336,  2.3783],\n",
      "        [ 1.7927,  2.1123],\n",
      "        [ 1.1994,  2.1694],\n",
      "        [ 3.1113,  3.1242],\n",
      "        [ 1.9708,  2.0585],\n",
      "        [ 1.1753,  3.0864],\n",
      "        [ 2.3572,  2.2642],\n",
      "        [ 2.7323,  1.6735],\n",
      "        [ 3.6940,  1.6194],\n",
      "        [ 1.2189,  2.9096],\n",
      "        [ 1.9916,  1.8752],\n",
      "        [ 1.7958,  0.0392],\n",
      "        [ 3.3591,  1.1597],\n",
      "        [ 1.5882,  2.9686],\n",
      "        [ 2.9219,  2.2787],\n",
      "        [ 2.8085,  3.8920],\n",
      "        [ 3.6078,  1.4371],\n",
      "        [ 1.8245,  1.6825],\n",
      "        [-0.3210,  1.1996],\n",
      "        [ 2.4412,  1.3701],\n",
      "        [-0.5228,  2.1342],\n",
      "        [ 0.8958,  2.8507],\n",
      "        [ 1.5564,  1.4308],\n",
      "        [ 1.9921,  0.4911],\n",
      "        [ 0.4837,  1.8332],\n",
      "        [ 0.6546,  2.2187],\n",
      "        [ 1.0512,  3.1374],\n",
      "        [ 0.7154,  1.3758],\n",
      "        [ 2.2646,  1.6937],\n",
      "        [ 3.5037,  0.9935],\n",
      "        [ 2.7129,  0.2082],\n",
      "        [ 2.9862,  1.1178],\n",
      "        [ 1.9089,  2.6447],\n",
      "        [ 1.2697,  1.4697],\n",
      "        [ 2.3720,  0.1434],\n",
      "        [ 2.1384,  2.2306],\n",
      "        [ 1.0389,  2.0939],\n",
      "        [ 1.1508,  1.4818],\n",
      "        [ 3.5648,  4.4204],\n",
      "        [ 2.7509,  3.5889],\n",
      "        [ 1.0138,  3.5279],\n",
      "        [ 3.0082,  0.6253],\n",
      "        [ 0.5329,  2.8579],\n",
      "        [ 2.8222, -0.0650],\n",
      "        [ 1.8678,  0.1242],\n",
      "        [ 1.9160,  0.7948],\n",
      "        [ 2.2723,  2.6555],\n",
      "        [ 2.2257,  0.9183],\n",
      "        [ 0.6720,  2.2471],\n",
      "        [ 2.7571,  2.3717],\n",
      "        [ 0.7964,  0.9610],\n",
      "        [ 0.9494,  1.8152],\n",
      "        [ 1.4210,  3.8577],\n",
      "        [ 1.6406,  2.6409],\n",
      "        [ 2.4602,  3.7691],\n",
      "        [ 3.8867,  0.9173],\n",
      "        [ 2.8660,  0.1859],\n",
      "        [ 0.2271,  2.2703],\n",
      "        [ 2.3974,  3.4096],\n",
      "        [ 2.1120,  2.9327],\n",
      "        [ 2.7773,  3.6448],\n",
      "        [ 0.8192,  3.1163],\n",
      "        [ 2.1550,  1.9977],\n",
      "        [ 2.2681,  2.1968],\n",
      "        [ 0.7289,  1.0184],\n",
      "        [ 1.7065,  1.1561],\n",
      "        [ 2.5307,  1.8518],\n",
      "        [ 2.1317,  2.9585],\n",
      "        [ 2.0889,  1.0126],\n",
      "        [ 3.7149,  0.7393],\n",
      "        [ 2.1821,  1.2747],\n",
      "        [ 0.8891,  2.3006],\n",
      "        [ 3.3292,  2.0869],\n",
      "        [ 1.7150,  2.2641],\n",
      "        [ 2.3189,  1.1661],\n",
      "        [ 1.8784,  2.5675],\n",
      "        [ 2.5953,  2.5841],\n",
      "        [ 1.2242,  1.4825],\n",
      "        [ 2.0842,  1.8685],\n",
      "        [-1.3942, -3.0347],\n",
      "        [-0.5043, -1.9736],\n",
      "        [-1.4336, -1.0145],\n",
      "        [-2.6154, -1.8621],\n",
      "        [-3.0213,  0.1762],\n",
      "        [-3.0728, -1.0746],\n",
      "        [-1.0981, -1.0195],\n",
      "        [-2.7431, -1.5290],\n",
      "        [-2.3178, -3.3081],\n",
      "        [-1.3371, -1.2419],\n",
      "        [-1.7873, -2.2932],\n",
      "        [-1.2995, -1.4435],\n",
      "        [-1.1423, -4.7427],\n",
      "        [-1.7521, -0.7409],\n",
      "        [-1.4195, -0.3110],\n",
      "        [-1.6021, -2.4470],\n",
      "        [-2.4821, -0.9365],\n",
      "        [-0.5889,  0.2771],\n",
      "        [-2.1268, -2.7328],\n",
      "        [-1.6939, -1.8555],\n",
      "        [-0.7474, -0.9272],\n",
      "        [-1.3364, -3.3380],\n",
      "        [-2.0538, -3.5982],\n",
      "        [-2.4611, -0.7625],\n",
      "        [-1.1917, -3.0889],\n",
      "        [-3.3285, -2.7095],\n",
      "        [-2.3281, -3.3752],\n",
      "        [-2.5705, -2.7645],\n",
      "        [-2.1323, -3.2658],\n",
      "        [-0.2147, -2.8300],\n",
      "        [-1.4779, -0.4143],\n",
      "        [-2.5722, -2.8360],\n",
      "        [-1.9299, -3.1628],\n",
      "        [-0.8807, -2.5259],\n",
      "        [-2.0787, -0.1474],\n",
      "        [-2.4587, -0.5107],\n",
      "        [-1.0432, -2.3406],\n",
      "        [-0.4584, -1.1814],\n",
      "        [-3.0900, -3.5074],\n",
      "        [-3.7143, -2.0041],\n",
      "        [-0.8038, -2.6357],\n",
      "        [-2.7066, -2.1690],\n",
      "        [-1.9230, -1.0406],\n",
      "        [-0.3679, -1.6040],\n",
      "        [-1.8700, -2.2239],\n",
      "        [-2.6935, -1.1233],\n",
      "        [-1.4522,  1.0091],\n",
      "        [-1.3370, -1.3205],\n",
      "        [-3.6716, -3.5091],\n",
      "        [-1.5821, -0.2085],\n",
      "        [-2.7773, -0.6933],\n",
      "        [-1.4364, -1.6402],\n",
      "        [-2.1224, -1.4350],\n",
      "        [-2.8907, -1.7660],\n",
      "        [-3.1053, -3.2292],\n",
      "        [-1.6349, -2.1942],\n",
      "        [-0.8065, -2.6410],\n",
      "        [-1.6334, -1.2351],\n",
      "        [-0.8155, -2.6149],\n",
      "        [ 0.6447, -2.6316],\n",
      "        [-0.1327, -3.3404],\n",
      "        [-1.3530, -2.6956],\n",
      "        [-2.3781, -1.7364],\n",
      "        [-1.2488, -1.3236],\n",
      "        [-3.9289, -1.0993],\n",
      "        [-4.2245, -1.5103],\n",
      "        [-2.6457,  0.2109],\n",
      "        [-2.4481, -4.2680],\n",
      "        [-2.9825, -1.2786],\n",
      "        [-3.4837, -2.2828],\n",
      "        [-0.5930, -2.2228],\n",
      "        [-1.6204, -2.9287],\n",
      "        [-2.2211, -0.9923],\n",
      "        [-2.0307, -1.1748],\n",
      "        [-1.9620,  0.1601],\n",
      "        [-1.8687, -2.3448],\n",
      "        [-1.9297, -0.9681],\n",
      "        [-1.8063, -1.5521],\n",
      "        [-1.9044, -3.3473],\n",
      "        [-3.3053, -2.5015],\n",
      "        [-1.6758, -2.3521],\n",
      "        [-2.7462, -2.5940],\n",
      "        [-0.5678, -1.0784],\n",
      "        [-2.5842, -1.7465],\n",
      "        [-1.9131, -3.2254],\n",
      "        [-1.5311, -1.8090],\n",
      "        [-1.7972, -2.2066],\n",
      "        [-2.4105, -2.9943],\n",
      "        [-3.6608, -1.1783],\n",
      "        [-1.3110, -1.6060],\n",
      "        [-1.2524, -2.1125],\n",
      "        [-1.1166, -2.0045],\n",
      "        [-3.1633, -1.4896],\n",
      "        [-1.3179, -1.5017],\n",
      "        [-2.3031, -2.4147],\n",
      "        [-2.1411, -3.1301],\n",
      "        [-3.5463, -2.6195],\n",
      "        [-1.0730, -1.1817],\n",
      "        [-0.0262, -2.3190],\n",
      "        [-2.7062, -1.1904]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset to feed into the model\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\tdef __init__(self, x, y):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t# TODO: implement the __getitem__ function.\n",
    "\t\treturn self.x[index], self.y[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# TODO: implement the __len__ function.\n",
    "\t\treturn self.x.shape[0]\n",
    "\n",
    "dataset = MyDataset(x, y)\n",
    "dataloder = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W Parameter containing:\n",
      "tensor([[-0.0009],\n",
      "        [-0.0062]], device='cuda:0', requires_grad=True)\n",
      "b Parameter containing:\n",
      "tensor([[0.]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "my_model = MyLinear(num_features, 1).to(device)\n",
    "for name, param in my_model.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=2e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together\n",
    "\n",
    "Since this is just a toy experiment, we do not need validation.\n",
    "\n",
    "In the following code, we expect to see the training loss decreasing to 0.001 or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.691425621509552\n",
      "epoch: 10, loss: 0.6890594959259033\n",
      "epoch: 20, loss: 0.6931712031364441\n",
      "epoch: 30, loss: 0.6931995153427124\n",
      "epoch: 40, loss: 0.6911658048629761\n",
      "epoch: 50, loss: 0.6928441524505615\n",
      "epoch: 60, loss: 0.6926918625831604\n",
      "epoch: 70, loss: 0.6915373802185059\n",
      "epoch: 80, loss: 0.6932061910629272\n",
      "epoch: 90, loss: 0.6909627914428711\n",
      "epoch: 100, loss: 0.6912457346916199\n",
      "epoch: 110, loss: 0.6927659511566162\n",
      "epoch: 120, loss: 0.6931945085525513\n",
      "epoch: 130, loss: 0.6931717991828918\n",
      "epoch: 140, loss: 0.6921714544296265\n",
      "epoch: 150, loss: 0.6932268142700195\n",
      "epoch: 160, loss: 0.6930086016654968\n",
      "epoch: 170, loss: 0.6925650835037231\n",
      "epoch: 180, loss: 0.6921565532684326\n",
      "epoch: 190, loss: 0.6925286054611206\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(200):\n",
    "    for batch_x, batch_y in dataloder:\n",
    "        # TODO: implement the training loop.\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        y_pred = my_model(batch_x)\n",
    "        loss = loss_function(y_pred, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch: {}, loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "# save the model\n",
    "\n",
    "torch.save(my_model.state_dict(), 'my_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0234]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model(torch.tensor([1.4746, 2.1494]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST Classification\n",
    "\n",
    "In this section, you will use PyTorch to implement a multi-layer perceptron (MLP) model for classifying handwritten digits using the MNIST dataset.\n",
    "\n",
    "\n",
    "1. Data Loading and Preprocessing:\n",
    "   - Utilize the `torchvision.datasets` module to load the MNIST dataset.\n",
    "   - Apply necessary transformations (like `ToTensor` and `Normalize`) to prepare the data for model training. These transformations ensure the data has the correct format and scales, helping with model convergence.\n",
    "   - Use a DataLoader with a suitable batch size to efficiently manage data feeding into the model.\n",
    "\n",
    "2. Architecture:\n",
    "   - Define a simple MLP model with PyTorch's `torch.nn.Module`. A suggested architecture is:\n",
    "     - An input layer that takes the flattened 28x28 pixel values (784 features).\n",
    "     - One or more hidden layers with ReLU activations for non-linearity.\n",
    "     - An output layer with softmax activation for multi-class classification.\n",
    "   - Make sure to initialize the model appropriately, especially if you're stacking multiple layers.\n",
    "\n",
    "3. Training:\n",
    "   - Set up an optimizer (like `Adam` or `SGD`) to minimize the model's error during training. You will also need a loss function, such as `CrossEntropyLoss`, which is well-suited for classification tasks.\n",
    "   - Write a training loop that performs the following steps:\n",
    "     - Forward pass: Feed batches through the model to obtain predictions.\n",
    "     - Compute the loss by comparing predictions with true labels.\n",
    "     - Backward pass: Calculate gradients for each model parameter.\n",
    "     - Update the model weights using the optimizer.\n",
    "   - Periodically log or print the training loss to track progress.\n",
    "\n",
    "4. Evaluation:\n",
    "   - After training, evaluate your model on the test set.\n",
    "   - Compute and print the accuracy metric, and optionally, create a confusion matrix to analyze classification errors.\n",
    "\n",
    "\n",
    "MNIST: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False,\n",
    "                              transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        y = self.classifier(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, hidden_dim, output_dim, lr):\n",
    "    model = MLPModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(X, y, model, loss_fn, optimizer):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    X = torch.flatten(X, start_dim=1)\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_batch(X, y, model, loss_fn):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    X = torch.flatten(X, start_dim=1)\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    _, predictions = torch.max(y_pred, dim=-1)\n",
    "    acc = torch.mean((predictions == y).float())\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(train_loader, test_loader, model, loss_fn, optimizer):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        X, y = batch\n",
    "        train_loss = train_batch(X, y, model, loss_fn, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "    train_loss = np.mean(train_losses)\n",
    "\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    model.eval()\n",
    "    for batch in test_loader:\n",
    "        X, y = batch\n",
    "        val_loss, val_acc = val_batch(X, y, model, loss_fn)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = np.mean(val_accs)\n",
    "\n",
    "    return train_loss, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 1/30 [00:13<06:45, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.6957205715262966, 'val_loss': 0.38625431532211013, 'val_acc': 0.892523987206823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 2/30 [00:27<06:24, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.29338395139973633, 'val_loss': 0.31169836352795743, 'val_acc': 0.9086820362473348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 3/30 [00:41<06:10, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.2320212929681608, 'val_loss': 0.2749121738240313, 'val_acc': 0.9210754264392325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 4/30 [00:54<05:56, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.19067894546374395, 'val_loss': 0.25737007730193673, 'val_acc': 0.9246068763326226}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 5/30 [01:07<05:36, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.15982278849288917, 'val_loss': 0.24564853437177375, 'val_acc': 0.925856210021322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 6/30 [01:21<05:26, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.13261709618530457, 'val_loss': 0.2211876119048134, 'val_acc': 0.9349347014925373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  23%|██▎       | 7/30 [01:36<05:19, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.11273665672796927, 'val_loss': 0.2053142958489467, 'val_acc': 0.9403817963752665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 8/30 [01:49<05:03, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.09562928785991137, 'val_loss': 0.2044579667011415, 'val_acc': 0.9400486407249466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 9/30 [02:03<04:48, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.08155119477231411, 'val_loss': 0.1924660420819704, 'val_acc': 0.9433302238805971}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 10/30 [02:17<04:34, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.06923356788695618, 'val_loss': 0.1897054885217209, 'val_acc': 0.9440798240938166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  37%|███▋      | 11/30 [02:30<04:20, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.05949985046698979, 'val_loss': 0.18832434516852853, 'val_acc': 0.9443296908315565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 12/30 [02:44<04:06, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.05064542868002585, 'val_loss': 0.1777059827861227, 'val_acc': 0.9483775319829424}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  43%|████▎     | 13/30 [02:57<03:51, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.04229790791513244, 'val_loss': 0.17825672527162562, 'val_acc': 0.9482942430703625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 14/30 [03:12<03:40, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.03659018030639287, 'val_loss': 0.1736681545652183, 'val_acc': 0.949243736673774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 15/30 [03:26<03:29, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.03150295886466173, 'val_loss': 0.17646921583603242, 'val_acc': 0.9480610341151386}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 16/30 [03:41<03:18, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.02670413787791114, 'val_loss': 0.17714710683283358, 'val_acc': 0.949043843283582}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 17/30 [03:55<03:05, 14.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.022401332813700672, 'val_loss': 0.17306628556542797, 'val_acc': 0.9508095682302772}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 18/30 [04:09<02:48, 14.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.019431120692307402, 'val_loss': 0.1738017564334138, 'val_acc': 0.9506596481876333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  63%|██████▎   | 19/30 [04:23<02:34, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.016778551239318623, 'val_loss': 0.1730073179233882, 'val_acc': 0.9510261194029851}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 20/30 [04:36<02:18, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.014155070487243734, 'val_loss': 0.17162311212497272, 'val_acc': 0.9525919509594882}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 21/30 [04:50<02:03, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.01228079282542228, 'val_loss': 0.1761489882830035, 'val_acc': 0.9518090351812367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 22/30 [05:04<01:51, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.010887570640629833, 'val_loss': 0.17780822936022508, 'val_acc': 0.950992803837953}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  77%|███████▋  | 23/30 [05:18<01:37, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.009358486710828106, 'val_loss': 0.17626704110991462, 'val_acc': 0.9518923240938166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 24/30 [05:32<01:23, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.008076939132705236, 'val_loss': 0.1764729437666192, 'val_acc': 0.953125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  83%|████████▎ | 25/30 [05:46<01:09, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.007156806895628002, 'val_loss': 0.1769299662349545, 'val_acc': 0.9536913646055437}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 26/30 [06:00<00:56, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.006432814277400067, 'val_loss': 0.1828620841432892, 'val_acc': 0.9526086087420043}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 27/30 [06:14<00:41, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.005634725412686065, 'val_loss': 0.18419318973371732, 'val_acc': 0.9526918976545842}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 28/30 [06:27<00:27, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.005009366946805055, 'val_loss': 0.18187842448847047, 'val_acc': 0.9529917377398721}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  97%|█████████▋| 29/30 [06:41<00:13, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.004405561816777773, 'val_loss': 0.1828549435882986, 'val_acc': 0.9534414978678039}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 30/30 [06:55<00:00, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.003948740183248238, 'val_loss': 0.18400734477806271, 'val_acc': 0.9535581023454158}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "model, loss_fn, optimizer = get_model(1 * 28 * 28, 512, 10, 2e-4)\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc='Epoch'):\n",
    "    train_loss, val_loss, val_acc = train(\n",
    "        train_loader, test_loader, model, loss_fn, optimizer)\n",
    "    tqdm.write(str({\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
